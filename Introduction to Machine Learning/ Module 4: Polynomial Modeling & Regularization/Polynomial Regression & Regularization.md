Polynomial Regression & Regularization
Overview
Last week, we looked at how to train a linear model to fit data. However, linear models are restricted to fitting a straight line to any data, which is not sufficiently expressive when it comes to fitting more interesting (i.e., complex and non-linear) data. It turns out, we can fit non-linear data while still using the ideas from our linear regression algorithms we learned last week. To do so, we  we can simply transform our input features with nonlinear functions. Specifically we will look at transforming our features using a polynomial function to create a polynomial model (see below image).

<img width="1075" alt="Screenshot 2025-06-24 at 12 45 29â€¯PM" src="https://github.com/user-attachments/assets/083c4892-3c0c-40fd-acf1-d5f570bd0e55" />

Perp Material
Please read through the notes while also reviewing any of the required videos at the same time. The goal is to read a section of the notes and then watch the corresponding videos for that section (if there are any)! Videos will be posted on the following pages. See next page or the link below to  download the note which needs to be opened in Jupyter Notebook.

note-polynomial-regression-and-regularization.ipynb Download note-polynomial-regression-and-regularization.ipynb 

Objectives
The objectives of this week's module are 

MO1. Learn how to extend a linear model by transforming it to polynomial regression
MO2. Learn the definition of overfitting and observe when it happens with polynomial regression
MO3. Learn the regularization and ridge regression which helps to reduce overfitting
MO4. Practice implementing and using polynomial regression and regularization.

